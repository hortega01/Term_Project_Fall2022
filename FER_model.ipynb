{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emojify_project_through_graph.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hortega01/Term_Project_Fall2022/blob/main/FER_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Meh9wc4zdoQT"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"archive.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT9qRwU8U5hc"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S92aXPw8ouRb"
      },
      "source": [
        "train_dir = 'train'\n",
        "val_dir = 'test'\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(48,48),\n",
        "        batch_size=64,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=(48,48),\n",
        "        batch_size=64,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "base_model = tf.keras.applications.ResNet50(input_shape=(48,48,3),\n",
        "                                            include_top=False,weights=\"imagenet\")"
      ],
      "metadata": {
        "id": "dNQz6I77FA4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t74GyVFJU5zy"
      },
      "source": [
        "emotion_model = Sequential()\n",
        "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
        "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.25))\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.25))\n",
        "emotion_model.add(Flatten())\n",
        "emotion_model.add(Dense(1024, activation='relu'))\n",
        "emotion_model.add(Dropout(0.5))\n",
        "emotion_model.add(Dense(7, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndB4aIimU5o3"
      },
      "source": [
        "emotion_model.compile(loss='categorical_crossentropy',\n",
        "optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\n",
        "emotion_model_info = emotion_model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=28709 // 64,\n",
        "        epochs=50,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=7178 // 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udLyFoZ7XiW9"
      },
      "source": [
        "#Saving the model\n",
        "emotion_model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpqMYqG_M4oV"
      },
      "source": [
        "from keras.models import load_model\n",
        "emotion_model = load_model('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pazcXGdiM8v_"
      },
      "source": [
        "def emotion_analysis(emotions):\n",
        "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
        "    y_pos = np.arange(len(objects))\n",
        "    \n",
        "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
        "    plt.xticks(y_pos, objects)\n",
        "    plt.ylabel('percentage')\n",
        "    plt.title('emotion')\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3hXn_ASNO0V"
      },
      "source": [
        "#CODE for Capturing an image on Colab from here: https://colab.research.google.com/notebook#fileId=1OnUy6eFE7XhdfGfAHDCqQxpwueTOj_NO\n",
        "\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELxE3d9nwjjm"
      },
      "source": [
        "take_photo()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMyrDnhWX_Zj"
      },
      "source": [
        "import cv2\n",
        "            \n",
        "def facecrop(image):  \n",
        "    facedata = '/content/haarcascade_frontalface_alt.xml'\n",
        "    cascade = cv2.CascadeClassifier(facedata)\n",
        "\n",
        "    img = cv2.imread(image)\n",
        "\n",
        "    try:\n",
        "    \n",
        "        minisize = (img.shape[1],img.shape[0])\n",
        "        miniframe = cv2.resize(img, minisize)\n",
        "\n",
        "        faces = cascade.detectMultiScale(miniframe)\n",
        "\n",
        "        for f in faces:\n",
        "            x, y, w, h = [ v for v in f ]\n",
        "            cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
        "\n",
        "            sub_face = img[y:y+h, x:x+w]\n",
        "\n",
        "            \n",
        "            cv2.imwrite('capture.jpg', sub_face)\n",
        "            #print (\"Writing: \" + image)\n",
        "\n",
        "    except Exception as e:\n",
        "        print (e)\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    facecrop('/content/photo.jpg')\n",
        "\n",
        "#Testing a file.\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "file = '/content/capture.jpg'\n",
        "true_image = image.load_img(file)\n",
        "img = image.load_img(file, color_mode=\"grayscale\", target_size=(48, 48))\n",
        "\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis = 0)\n",
        "\n",
        "x /= 255\n",
        "\n",
        "custom = emotion_model.predict(x)\n",
        "emotion_analysis(custom[0])\n",
        "\n",
        "x = np.array(x, 'float32')\n",
        "x = x.reshape([48, 48]);\n",
        "\n",
        "\n",
        "plt.imshow(true_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}